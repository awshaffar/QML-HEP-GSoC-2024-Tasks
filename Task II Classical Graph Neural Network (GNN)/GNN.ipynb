{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task II: Classical Graph Neural Network (GNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Task II, you will use ParticleNet’s data for Quark/Gluon jet classification available [here](https://zenodo.org/records/3164691#.YigdGt9MHrB) with its corresponding description.\n",
    "- Choose 2 Graph-based architectures of your choice to classify jets as being quarks or gluons. Provide a description on what considerations you have taken to project this point-cloud dataset to a set of interconnected nodes and edges. \n",
    "- Discuss the resulting performance of the 2 chosen architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 16:49:01.029289: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-01 16:49:01.032044: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-01 16:49:01.059881: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-01 16:49:01.660361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tf_keras_model import get_particle_net_lite, get_particle_net\n",
    "from tensorflow import keras\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='[%(asctime)s] %(levelname)s: %(message)s')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-01 17:06:01--  ftp://https/\n",
      "           => ‘./data/.listing’\n",
      "Resolving https (https)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘https’\n",
      "//: Scheme missing.\n",
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2024-04-01 17:06:03--  https://zenodo.org/record/3164691/files/QG_jets.npz\n",
      "Resolving zenodo.org (zenodo.org)... 188.184.103.159, 188.184.98.238, 188.185.79.172, ...\n",
      "Connecting to zenodo.org (zenodo.org)|188.184.103.159|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
      "Location: /records/3164691/files/QG_jets.npz [following]\n",
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2024-04-01 17:06:04--  https://zenodo.org/records/3164691/files/QG_jets.npz\n",
      "Reusing existing connection to zenodo.org:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 106689379 (102M) [application/octet-stream]\n",
      "Saving to: ‘./data/QG_jets.npz’\n",
      "\n",
      "QG_jets.npz         100%[===================>] 101.75M  2.95MB/s    in 3m 45s  \n",
      "\n",
      "2024-04-01 17:09:49 (464 KB/s) - ‘./data/QG_jets.npz’ saved [106689379/106689379]\n",
      "\n",
      "FINISHED --2024-04-01 17:09:49--\n",
      "Total wall clock time: 3m 48s\n",
      "Downloaded: 1 files, 102M in 3m 45s (464 KB/s)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "!wget https: // zenodo.org/record/3164691/files/QG_jets.npz -P ./data\n",
    "dataset = np.load('./data/QG_jets.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X', 'y']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what keys are present in the dataset\n",
    "list(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data as per keys\n",
    "x = dataset['X']\n",
    "y = dataset['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "As per the information of the dataset from here\n",
    "\n",
    "X: (100000,M,4), exactly 50k quark and 50k gluon jets, randomly sorted, where M is the max multiplicity of the jets in that file (other jets have been padded with zero-particles), and the features of each particle are its pt, rapidity, azimuthal angle, and pdgid.\n",
    "\n",
    "y: (100000,), an array of labels for the jets where gluon is 0 and quark is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding labels is needed else the following error\n",
    "# ValueError: Shapes (None, 1) and (None, 2) are incompatible\n",
    "y = keras.utils.to_categorical(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 139, 4) (70000, 2)\n",
      "(15000, 139, 4) (15000, 2)\n",
      "(15000, 139, 4) (15000, 2)\n"
     ]
    }
   ],
   "source": [
    "x, y = shuffle(x, y, random_state=0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.30, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 139)\n",
      "[   29.20243269    27.50561143    30.26089051   220.41819997\n",
      "    27.95042087    28.15969933   329.0687446     27.57628735\n",
      "  -206.06003465   218.08468374    26.41602355    27.02195013\n",
      "    31.79622486    26.59246689    26.88924931  -202.09822736\n",
      "    26.71899363    31.23462352  -310.42681747    27.70451205\n",
      "    30.7169403   -198.56554041  2233.77838649    36.42720615\n",
      "    29.23621805  -187.38676832    33.46071738   268.17256202\n",
      "    32.3521241  -2054.01856237   118.7019814     56.63953271\n",
      "   151.53934524    57.07618763     0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.             0.\n",
      "     0.             0.             0.        ]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(70000, 139, 1)\n"
     ]
    }
   ],
   "source": [
    "# mask\n",
    "# find the maximum length vector in for each sample in 10000 samples with maximum number of non-zero values\n",
    "mask_train = np.sum(x_train, axis=2)\n",
    "print(mask_train.shape)\n",
    "print(mask_train[0])\n",
    "\n",
    "# make the array binary\n",
    "mask_train = np.array(mask_train != 0, np.float32)\n",
    "print(mask_train[0])\n",
    "\n",
    "# reshape mask for a third axis\n",
    "mask_train = mask_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "print(mask_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 139, 1)\n"
     ]
    }
   ],
   "source": [
    "# mask\n",
    "# find the maximum length vector in for each sample in 10000 samples with maximum number of non-zero values\n",
    "mask_val = np.sum(x_val, axis=2)\n",
    "\n",
    "# make the array binary\n",
    "mask_val = np.array(mask_val != 0, np.float32)\n",
    "\n",
    "# reshape mask for a third axis\n",
    "mask_val = mask_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
    "print(mask_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 139, 1)\n"
     ]
    }
   ],
   "source": [
    "# mask\n",
    "# find the maximum length vector in for each sample in 10000 samples with maximum number of non-zero values\n",
    "mask_test = np.sum(x_test, axis=2)\n",
    "\n",
    "# make the array binary\n",
    "mask_test = np.array(mask_test != 0, np.float32)\n",
    "\n",
    "# reshape mask for a third axis\n",
    "mask_test = mask_val.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "print(mask_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = {\n",
    "    'points': x_train[:, :, 1:3],\n",
    "    'features': x_train,\n",
    "    'mask': mask_train\n",
    "}\n",
    "\n",
    "test_dataset = {\n",
    "    'points': x_test[:, :, 1:3],\n",
    "    'features': x_test,\n",
    "    'mask': mask_test\n",
    "}\n",
    "\n",
    "val_dataset = {\n",
    "    'points': x_val[:, :, 1:3],\n",
    "    'features': x_val,\n",
    "    'mask': mask_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'points': (139, 2), 'features': (139, 4), 'mask': (139, 1)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes = {\n",
    "    'points': x_train[:, :, 1:3].shape[1:],\n",
    "    'features': x_train.shape[1:],\n",
    "    'mask': mask_train.shape[1:]\n",
    "}\n",
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# particle net lite\u001b[39;00m\n\u001b[1;32m      2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_particle_net_lite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codes/QML-HEP-GSoC-2024-Tasks/Task II Classical Graph Neural Network (GNN)/tf_keras_model.py:180\u001b[0m, in \u001b[0;36mget_particle_net_lite\u001b[0;34m(num_classes, input_shapes)\u001b[0m\n\u001b[1;32m    178\u001b[0m features \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39minput_shapes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m input_shapes \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    179\u001b[0m mask \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39minput_shapes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m input_shapes \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_particle_net_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mParticleNet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[points, features, mask], outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParticleNet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/codes/QML-HEP-GSoC-2024-Tasks/Task II Classical Graph Neural Network (GNN)/tf_keras_model.py:90\u001b[0m, in \u001b[0;36m_particle_net_base\u001b[0;34m(points, features, mask, setting, name)\u001b[0m\n\u001b[1;32m     87\u001b[0m     features \u001b[38;5;241m=\u001b[39m points\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 1 if valid\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     coord_shift \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmultiply(\u001b[38;5;241m999.\u001b[39m, tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39mequal(mask, \u001b[38;5;241m0\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# make non-valid positions to 99\u001b[39;00m\n\u001b[1;32m     93\u001b[0m fts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mBatchNormalization(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_fts_bn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m name)(tf\u001b[38;5;241m.\u001b[39mexpand_dims(features, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/codes/QML-HEP-GSoC-2024-Tasks/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/codes/QML-HEP-GSoC-2024-Tasks/.venv/lib/python3.11/site-packages/keras/src/backend/common/keras_tensor.py:91\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "# particle net lite\n",
    "num_classes = 2\n",
    "model = get_particle_net_lite(num_classes, shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
